version: "3.9"

services:
  llm:
    image: ghcr.io/ggml-org/llama.cpp:full
    container_name: embedded-llm
    command: >
      --server
      --model /models/phi-2-q4_K_M.gguf
      --n-gpu-layers 0
      --threads 4
      --host 0.0.0.0
      --port 8080
    volumes:
      # Adjust this path to wherever your shared models directory lives.
      # Assuming you moved it to the monorepo root:
      #   ai-agent-experiments/models
      - ../models:/models
    ports:
      - "8080:8080"

  agent:
    build: ./agent
    container_name: embedded-agent
    depends_on:
      - llm
      - piper
    environment:
      # Where the agent finds the LLM HTTP server
      LLM_BASE_URL: "http://llm:8080"
      # Where markdown docs are mounted in the container
      DOCS_DIR: "/docs"
      # Piper TTS endpoint (container-to-container URL)
      TTS_PIPER_URL: "http://piper:5000"
      # Where to write audio files inside the container
      TTS_AUDIO_DIR: "/audio"
      # Where personaâ†’voice mapping lives inside the container
      PERSONA_VOICE_CONFIG: "/app/config/persona_voices.yaml"
      # Default Piper voice if a persona is not mapped
      TTS_PIPER_DEFAULT_VOICE: "en_US-kathleen-low"
    volumes:
      # Mount app code so you can iterate without rebuilding every change
      - ./agent/app:/app/app
      # Markdown docs
      - ./docs:/docs:ro
      # Audio output (wav files come out here on the host)
      - ./audio:/audio
      # Shared models for any future use (read-only)
      - ../models:/models:ro
    ports:
      - "8001:8001"

  piper:
    image: artibex/piper-http:latest
    container_name: embedded-piper
    restart: unless-stopped
    environment:
      # This tells the image which voice model to download/use
      MODEL_DOWNLOAD_LINK: "https://huggingface.co/rhasspy/piper-voices/resolve/v1.0.0/en/en_US/kusal/medium/en_US-kusal-medium.onnx?download=true"
    ports:
      - "5000:5000"
    volumes:
      # Optional: cache model/data on the host so startup is faster after first run
      - ./piper-data:/data

  # tts: -- IGNORE left in as a debug tool for TTS ---
  #   build: ./tts
  #   container_name: embedded-tts
  #   ports:
  #     - "8002:8000"
